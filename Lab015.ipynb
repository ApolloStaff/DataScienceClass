{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=darkred>Laboratory 15: Pandas for Butter! </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble script block to identify host, user, and kernel\n",
    "import sys\n",
    "! hostname\n",
    "! whoami\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full name: \n",
    "## R#: \n",
    "## Title of the notebook:\n",
    "## Date:\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/1280px-Pandas_logo.svg.png) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=purple>Pandas</font>\n",
    "A data table is called a `DataFrame` in pandas (and other programming environments too).\n",
    "\n",
    "The figure below from https://pandas.pydata.org/docs/getting_started/index.html illustrates a dataframe model:\n",
    "\n",
    "![](https://pandas.pydata.org/docs/_images/01_table_dataframe.svg) \n",
    "\n",
    "Each column and each row in a dataframe is called a series, the header row, and index column are special.\n",
    "\n",
    "To use pandas, we need to import the module, generally pandas has numpy as a dependency so it also must be imported\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Importing NumPy library as \"np\"\n",
    "import pandas as pd #Importing Pandas library as \"pd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <font color=darkgreen>Dataframe-structure using primative python</font>\n",
    "\n",
    "First lets construct a dataframe like object using python primatives.\n",
    "We will construct 3 lists, one for row names, one for column names, and one for the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytabular = np.random.randint(1,100,(5,4))\n",
    "myrowname = ['A','B','C','D','E']\n",
    "mycolname = ['W','X','Y','Z']\n",
    "mytable = [['' for jcol in range(len(mycolname)+1)] for irow in range(len(myrowname)+1)] #non-null destination matrix, note the implied loop construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mytabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above builds a placeholder named `mytable` for the psuedo-dataframe.\n",
    "Next we populate the table, using a for loop to write the column names in the first row, row names in the first column, and the table fill for the rest of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for irow in range(1,len(myrowname)+1): # write the row names\n",
    "    mytable[irow][0]=myrowname[irow-1]\n",
    "for jcol in range(1,len(mycolname)+1): # write the column names\n",
    "    mytable[0][jcol]=mycolname[jcol-1]  \n",
    "for irow in range(1,len(myrowname)+1): # fill the table (note the nested loop)\n",
    "    for jcol in range(1,len(mycolname)+1):\n",
    "        mytable[irow][jcol]=mytabular[irow-1][jcol-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets print the table out by row and we see we have a very dataframe-like structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for irow in range(0,len(myrowname)+1):\n",
    "    print(mytable[irow][0:len(mycolname)+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query by row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mytable[3][0:len(mycolname)+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for irow in range(0,len(myrowname)+1):  #cannot use implied loop in a column slice\n",
    "    print(mytable[irow][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by row+column index; sort of looks like a spreadsheet syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' ',mytable[0][3])\n",
    "print(mytable[3][0],mytable[3][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### <font color=darkgreen>Create a proper dataframe</font>\n",
    "We will now do the same using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1,100,(5,4)), ['A','B','C','D','E'], ['W','X','Y','Z'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also turn our table into a dataframe, notice how the constructor adds header row and index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(mytable)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get proper behavior, we can just reuse our original objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(mytabular,myrowname,mycolname)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Getting the shape of dataframes</font>\n",
    "\n",
    "The shape method will return the row and column rank (count) of a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Appending new columns</font>\n",
    "To append a column simply assign a value to a new column name to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new']= 'NA'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Appending new rows</font>\n",
    "A bit trickier but we can create a copy of a row and concatenate it back into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newrow = df.loc[['E']].rename(index={\"E\": \"X\"}) # create a single row, rename the index\n",
    "newtable = pd.concat([df,newrow]) # concatenate the row to bottom of df - note the syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Removing Rows and Columns</font>\n",
    "\n",
    "To remove a column is straightforward, we use the drop method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable.drop('new', axis=1, inplace = True)\n",
    "newtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove a row, you really got to want to, easiest is probablty to create a new dataframe with the row removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable = newtable.loc[['A','B','D','E','X']] # select all rows except C\n",
    "newtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Indexing</font>\n",
    "We have already been indexing, but a few examples follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable['X'] #Selecing a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable[['X','W']] #Selecing multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable.loc['E'] #Selecing rows based on label via loc[ ] indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable.loc[['E','X','B']] #Selecing multiple rows based on label via loc[ ] indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtable.loc[['B','E','D'],['X','Y']] #Selecting elemens via both rows and columns via loc[ ] indexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Conditional Selection</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'col1':[1,2,3,4,5,6,7,8],\n",
    "                   'col2':[444,555,666,444,666,111,222,222],\n",
    "                   'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What fruit corresponds to the number 555 in ‘col2’?\n",
    "\n",
    "df[df['col2']==555]['col3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What fruit corresponds to the minimum number in ‘col2’?\n",
    "\n",
    "df[df['col2']==df['col2'].min()]['col3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Descriptor Functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe from a dictionary\n",
    "\n",
    "df = pd.DataFrame({'col1':[1,2,3,4,5,6,7,8],\n",
    "                   'col2':[444,555,666,444,666,111,222,222],\n",
    "                   'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkblue>`head` method</font>\n",
    "\n",
    "\n",
    "Returns the first few rows, useful to infer structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns only the first five rows\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkblue>`info` method</font>\n",
    "\n",
    "Returns the data model (data column count, names, data types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info about the dataframe\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkblue>`describe` method</font>\n",
    "\n",
    "Returns summary statistics of each numeric column.  \n",
    "Also returns the minimum and maximum value in each column, and the IQR (Interquartile Range).  \n",
    "Again useful to understand structure of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics of the dataframe\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=darkblue>Counting and Sum methods</font>\n",
    "\n",
    "\n",
    "There are also methods for counts and sums by specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].sum() #Sum of a specified column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `unique` method returns a list of unique values (filters out duplicates in the list, underlying dataframe is preserved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].unique() #Returns the list of unique values along the indexed column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nunique` method returns a count of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].nunique() #Returns the total number of unique values along the indexed column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `value_counts()` method returns the count of each unique value (kind of like a histogram, but each value is the bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col2'].value_counts()  #Returns the number of occurences of each unique value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Using functions in dataframes - symbolic apply</font>\n",
    "\n",
    "The power of pandas is an ability to apply a function to each element of a dataframe series (or a whole frame) by a technique called symbolic (or synthetic programming) application of the function.\n",
    "\n",
    "Its pretty complicated but quite handy, best shown by an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def times2(x):  # A prototype function to scalar multiply an object x by 2\n",
    "    return(x*2)\n",
    "\n",
    "print(df)\n",
    "print('Apply the times2 function to col2')\n",
    "df['col2'].apply(times2) #Symbolic apply the function to each element of column col2, result is another dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Sorts</font>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('col2', ascending = True) #Sorting based on columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Aggregating (Grouping Values) dataframe contents</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe from a dictionary\n",
    "\n",
    "data = {\n",
    "    'key' : ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'data1' : [1, 2, 3, 4, 5, 6],\n",
    "    'data2' : [10, 11, 12, 13, 14, 15],\n",
    "    'data3' : [20, 21, 22, 13, 24, 25]\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and summing values in all the columns based on the column 'key'\n",
    "\n",
    "df1.groupby('key').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and summing values in the selected columns based on the column 'key'\n",
    "\n",
    "df1.groupby('key')[['data1', 'data2']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Filtering out missing values</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataframe from a dictionary\n",
    "\n",
    "df = pd.DataFrame({'col1':[1,2,3,4,None,6,7,None],\n",
    "                   'col2':[444,555,None,444,666,111,None,222],\n",
    "                   'col3':['orange','apple','grape','mango','jackfruit','watermelon','banana','peach']})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we drop any row that contains a `NaN` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.dropna()\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we replace `NaN` codes with some value, in this case 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled1 = df.fillna(0)\n",
    "df_filled1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we replace `NaN` codes with some value, in this case the mean value of of the column in which the missing value code resides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled2 = df.fillna(df['col1'].mean())\n",
    "df_filled2 = df.fillna(df['col2'].mean())\n",
    "df_filled2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Reading a File into a Dataframe</font>\n",
    "\n",
    "Pandas has methods to read common file types, such as `csv`,`xlsx`, and `json`.  Ordinary text files are also quite manageable.\n",
    "\n",
    "On a machine you control you can write script to retrieve files from the internet and process them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "readfilecsv = pd.read_csv('CSV_ReadingFile.csv')  #Reading a .csv file\n",
    "print(readfilecsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to reading and writing .csv files, you can also read and write .xslx files as below (useful to know this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readfileexcel = pd.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1', engine='openpyxl') #Reading a .xlsx file\n",
    "print(readfileexcel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Writing a dataframe to file</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and writing to a .csv file\n",
    "readfilecsv = pd.read_csv('CSV_ReadingFile.csv')\n",
    "readfilecsv.to_csv('CSV_WritingFile1.csv')\n",
    "readfilecsv = pd.read_csv('CSV_WritingFile1.csv')\n",
    "print(readfilecsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and writing to a .csv file by excluding row labels \n",
    "readfilecsv = pd.read_csv('CSV_ReadingFile.csv')\n",
    "readfilecsv.to_csv('CSV_WritingFile2.csv', index = False)\n",
    "readfilecsv = pd.read_csv('CSV_WritingFile2.csv')\n",
    "print(readfilecsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and writing to a .xlsx file\n",
    "readfileexcel = pd.read_excel('Excel_ReadingFile.xlsx', sheet_name='Sheet1',  engine='openpyxl')\n",
    "readfileexcel.to_excel('Excel_WritingFile.xlsx', sheet_name='MySheet',  engine='openpyxl')\n",
    "readfileexcel = pd.read_excel('Excel_WritingFile.xlsx', sheet_name='MySheet',  engine='openpyxl')\n",
    "print(readfileexcel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Plotting using Pandas</font>\n",
    "Pandas uses the `plot()` method to create diagrams.\n",
    "\n",
    "Import Pyplot from Matplotlib and visualize your DataFrame:\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Plot\n",
    "\n",
    "To create different kinds of plots and add details like a title, specify the `kind` argument:\n",
    "\n",
    "```python\n",
    "kind = 'scatter'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a scatter plot requires both an x-axis and a y-axis. In the example below, we'll use **\"Duration\"** for the **x-axis** and **\"Calories\"** for the **y-axis**. Our dataframe is denoted as DF and its dataframe of **Food Items**.\n",
    "\n",
    "```python\n",
    "x = 'Duration'\n",
    "y = 'Calories'\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "DF.plot(kind='scatter', x='Duration', y='Calories', title='Food Items')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    ">#####         FOOD ITEMS\n",
    "![Scatter Plot](https://www.w3schools.com/python/pandas/img_pandas_plot_scatter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=purple>Pandas - Data Correlations</font>\n",
    "The `corr()` method calculates the relationship between each column in your data set.\n",
    "For example to show relationship between the columns in a dataframe - DF:\n",
    "\n",
    "```python\n",
    "DF.corr()\n",
    "            Duration     Pulse  Maxpulse  Calories\n",
    "  Duration  1.000000 -0.155408  0.009403  0.922721\n",
    "  Pulse    -0.155408  1.000000  0.786535  0.025120\n",
    "  Maxpulse  0.009403  0.786535  1.000000  0.203814\n",
    "  Calories  0.922721  0.025120  0.203814  1.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The result of the `corr()` method is a table with numbers that represent the strength of the relationship between two columns.\n",
    "\n",
    "The correlation coefficient ranges from `-1` to `1`:\n",
    "- `1` means a perfect correlation: each time a value increases in the first column, the value in the second column also increases.\n",
    "- `0.9` indicates a strong positive relationship: if you increase one value, the other is likely to increase as well.\n",
    "- `-0.9` represents a strong inverse relationship: if you increase one value, the other is likely to decrease.\n",
    "- `0.2` indicates a weak relationship: an increase in one value does not imply an increase in the other.\n",
    "\n",
    "### What is a Good Correlation?\n",
    "\n",
    "The significance of a correlation depends on the context, but generally, a correlation of at least `0.6` (or `-0.6`) is considered strong.\n",
    "\n",
    "#### Perfect Correlation\n",
    "\n",
    "- **\"Duration\" and \"Duration\"**: Correlation of `1.000000`, as a column is always perfectly correlated with itself.\n",
    "\n",
    "#### Good Correlation\n",
    "\n",
    "- **\"Duration\" and \"Calories\"**: Correlation of `0.922721`, indicating a very strong relationship. This suggests that longer workouts are associated with burning more calories, and vice versa.\n",
    "\n",
    "#### Bad Correlation\n",
    "\n",
    "- **\"Duration\" and \"Maxpulse\"**: Correlation of `0.009403`, showing a very weak relationship. This implies that the duration of the workout does not predict max pulse, and vice versa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Pandas of Data  \n",
    "1. Pandas library supports two major types of data structures: Series, DataFrames. Discuss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file OECD.csv contains information about the gross domestic product (GDP) per capita for different countries belonging to the OECD.  The table shows the current GDP per capita from 1991 to 2021 of each country. (Data from: https://data.oecd.org/gdp/gross-domestic-product-gdp.htm#indicator-chart) <br>\n",
    "\n",
    "2. Import the pandas module. Load the data from OECD.csv into a Pandas dataframe called as \"OECD\".  The country name should show up as the row labels.\n",
    "Display the dataframe contents, summary of columns, and basic statistical description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check if there are any null values in the dataframe, if so, identify the columns that have null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run the below cell first which randomly selects a 10 year span. In a new cell, sort the data by the current GDP per capita.  Then plot a horizontal bar chart of the current GDP for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS CELL!!! to Continue \n",
    "import numpy as np\n",
    "i=np.random.randint(1991,2001)\n",
    "OECD=OECD[[str(i),str(i+10)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compute the difference between GDP per capita for the 10 year interval.  Place this data as a new column in the same dataframe.  Sort the dataframe by the GDP growth and display the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which country has the highest growth in GDP per capita?  Which had the smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create a dataframe that contains a subset of the countries that had negative growth of their GDP per capita.  You should use Pandas comparisons and selection operators.  Display the resulting dataframe contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Compute the Pearson correlation index between the GDP for the selected two columns in Task 2. Are the columns correlated? If so, how (weakly, strongly, etc.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## <font color=orange>This is a Pandas Cheat Sheet</font>\n",
    "\n",
    "![](https://i.pinimg.com/originals/39/08/5c/39085c27945ad3eb49e0de7dff6f0b0e.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "![](https://media2.giphy.com/media/5nj4ZZWl6QwneEaBX4/source.gif) <br>\n",
    "\n",
    "*Here are some of the resources used for creating this notebook:* \n",
    "\n",
    "- Pandas foundations. Retrieved February 15, 2021, from https://www.datacamp.com/courses/pandas-foundations <br>\n",
    "- Pandas tutorial. Retrieved February 15, 2021, from https://www.w3schools.com/python/pandas/default.asp <br>\n",
    "- Pandas tutorial: Dataframes in Python. Retrieved February 15, 2021, from https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python <br>\n",
    "\n",
    "*Here are some great reads on this topic:* \n",
    "- __\"Introduction to Pandas in Python\"__ available at *https://www.geeksforgeeks.org/introduction-to-pandas-in-python/<br>\n",
    "- __\"Pandas Introduction & Tutorials for Beginners\"__ by __Walker Rowe__, available at *https://www.bmc.com/blogs/pandas-basics/ <br>\n",
    "- __\"Using Pandas and Python to Explore Your Dataset\"__ by __Reka Horvath__ available at *https://realpython.com/pandas-python-explore-dataset/ <br>\n",
    "- __\"Python Pandas Tutorial: A Complete Introduction for Beginners\"__ by __George McIntire, Lauren Washington, and Brendan Martin__ available at *https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/ <br>\n",
    "\n",
    "\n",
    "*Here are some great videos on these topics:* \n",
    "- __\"Python: Pandas Tutorial | Intro to DataFrames\"__ by __Joe James__ available at *https://www.youtube.com/watch?v=e60ItwlZTKM <br>\n",
    "- __\"Complete Python Pandas Data Science Tutorial! (Reading CSV/Excel files, Sorting, Filtering, Groupby)\"__ by __Keith Galli__ available at *https://www.youtube.com/watch?v=vmEHCJofslg <br>\n",
    "- __\"What is Pandas? Why and How to Use Pandas in Python\"__ by __Python Programmer__ available at *https://www.youtube.com/watch?v=dcqPhpY7tWk <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.quotemaster.org/images/q/13084/1308445/i4.png)\n",
    "![](https://images.fineartamerica.com/images/artworkimages/mediumlarge/2/bad-panda-balazs-solti.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
